{
    "training_args": {
      "per_device_train_batch_size": 1,
      "gradient_accumulation_steps": 16,
      "learning_rate": 0.0002,
      "max_steps": 1000,
      "logging_steps": 10,
      "save_steps": 100,
      "save_total_limit": 2,
      "fp16": true,
      "bf16": false,
      "gradient_checkpointing": false,
      "optim": "paged_adamw_32bit",
      "warmup_ratio": 0.03,
      "lr_scheduler_type": "constant",
      "report_to": "none"
    }
  }
  