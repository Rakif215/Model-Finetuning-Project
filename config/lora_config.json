{
    "lora_config": {
      "r": 8,
      "target_modules": ["q_proj", "v_proj"],
      "lora_alpha": 16,
      "lora_dropout": 0.05,
      "bias": "none",
      "use_gradient_checkpointing": false,
      "random_state": 42,
      "use_rslora": false,
      "loftq_config": {}
    }
  }
  